train_file:  ['/content/FoodZ_Dataset/data/finetune/train_x-vlm_foodz_dataset.json.json']
val_file: '/content/FoodZ_Dataset/data/finetune/val_x-vlm_foodz_dataset.json'
test_file: '/content/FoodZ_Dataset/data/finetune/test_x-vlm_foodz_dataset.json'
image_root: '/content/FoodZ_Dataset/images/'


## Vision Encoder
vision_config: '/content/X-VLM-master/configs/config_swinB_384.json'

use_clip_vit: False
#image_res: 384
#patch_size: 16

use_swin: True
image_res: 384
patch_size: 32


## Text Encoder
use_roberta: False
text_config: '/content/X-VLM-master/configs/config_bert.json'  # ['/content/X-VLM-master/configs/config_bert.json', '/content/X-VLM-master/configs/config_roberta.json']
text_encoder: 'bert-base-uncased'  # ['data/bert-base-uncased', 'data/roberta-base']


## Training
batch_size_train: 8
batch_size_test: 8
batch_size_test_text: 64
max_tokens: 100
embed_dim: 256
temp: 0.07
k_test: 128


## Other Settings
optimizer: {opt: adamW, lr: 3e-5, weight_decay: 0.01, lr_mult: 2}
schedular: {sched: linear, lr: 3e-5, epochs: 10, num_warmup_steps: 0.1}
